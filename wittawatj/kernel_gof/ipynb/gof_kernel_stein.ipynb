{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to test and demonstrate `KernelSteinTest`. This implements the kernelized Stein discrepancy test of Chwialkowski et al., 2016 and Liu et al., 2016 in ICML 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'\n",
    "\n",
    "import kgof\n",
    "import kgof.data as data\n",
    "import kgof.density as density\n",
    "import kgof.goftest as gof\n",
    "import kgof.kernel as ker\n",
    "import kgof.util as util\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: p = Isotropic normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true p\n",
    "seed = 13\n",
    "d = \n",
    "# sample\n",
    "n = 800\n",
    "\n",
    "mean = np.zeros(d)\n",
    "variance = 1.0\n",
    "qmean = mean.copy()\n",
    "qmean[0] = 0\n",
    "qvariance = variance\n",
    "\n",
    "p = density.IsotropicNormal(mean, variance)\n",
    "ds = data.DSIsotropicNormal(qmean, qvariance)\n",
    "# ds = data.DSLaplace(d=d, loc=0, scale=1.0/np.sqrt(2))\n",
    "dat = ds.sample(n, seed=seed+1)\n",
    "X = dat.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "alpha = 0.01\n",
    "\n",
    "# Gaussian kernel with median heuristic\n",
    "sig2 = util.meddistance(X, subsample=1000)**2\n",
    "k = ker.KGauss(sig2)\n",
    "\n",
    "# inverse multiquadric kernel\n",
    "# From Gorham & Mackey 2017 (https://arxiv.org/abs/1703.01717)\n",
    "# k = ker.KIMQ(b=-0.5, c=1.0)\n",
    "\n",
    "bootstrapper = gof.bootstrapper_rademacher\n",
    "kstein = gof.KernelSteinTest(p, k, bootstrapper=bootstrapper, \n",
    "                             alpha=alpha, n_simulate=500, seed=seed+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kstein_result = kstein.perform_test(dat, return_simulated_stats=True,\n",
    "                                   return_ustat_gram=True)\n",
    "kstein_result\n",
    "#kstein.compute_stat(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('p-value: ', kstein_result['pvalue'])\n",
    "print('reject H0: ', kstein_result['h0_rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_stats = kstein_result['sim_stats']\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(sim_stats, bins=20, normed=True);\n",
    "plt.stem([kstein_result['test_stat']], [0.03], 'r-o', label='Stat')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test original implementation\n",
    "\n",
    "Original implementation of Chwialkowski et al., 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "def simulatepm(N, p_change):\n",
    "    '''\n",
    "\n",
    "    :param N:\n",
    "    :param p_change:\n",
    "    :return:\n",
    "    '''\n",
    "    X = np.zeros(N) - 1\n",
    "    change_sign = np.random.rand(N) < p_change\n",
    "    for i in range(N):\n",
    "        if change_sign[i]:\n",
    "            X[i] = -X[i - 1]\n",
    "        else:\n",
    "            X[i] = X[i - 1]\n",
    "    return X\n",
    "\n",
    "\n",
    "class _GoodnessOfFitTest:\n",
    "    def __init__(self, grad_log_prob, scaling=1):\n",
    "        #scaling is the sigma^2 as in exp(-|x_y|^2/2*sigma^2)\n",
    "        self.scaling = scaling*2\n",
    "        self.grad = grad_log_prob\n",
    "        # construct (slow) multiple gradient handle if efficient one is not given\n",
    "        \n",
    "\n",
    "    def grad_multiple(self, X):\n",
    "        #print self.grad\n",
    "        return np.array([(self.grad)(x) for x in X])\n",
    "    \n",
    "    def kernel_matrix(self, X):\n",
    "\n",
    "        # check for stupid mistake\n",
    "        assert X.shape[0] > X.shape[1]\n",
    "\n",
    "        sq_dists = squareform(pdist(X, 'sqeuclidean'))\n",
    "\n",
    "        K = np.exp(-sq_dists/ self.scaling)\n",
    "        return K\n",
    "\n",
    "    def gradient_k_wrt_x(self, X, K, dim):\n",
    "\n",
    "        X_dim = X[:, dim]\n",
    "        assert X_dim.ndim == 1\n",
    "\n",
    "        differences = X_dim.reshape(len(X_dim), 1) - X_dim.reshape(1, len(X_dim))\n",
    "\n",
    "        return -2.0 / self.scaling * K * differences\n",
    "\n",
    "    def gradient_k_wrt_y(self, X, K, dim):\n",
    "        return -self.gradient_k_wrt_x(X, K, dim)\n",
    "\n",
    "    def second_derivative_k(self, X, K, dim):\n",
    "        X_dim = X[:, dim]\n",
    "        assert X_dim.ndim == 1\n",
    "\n",
    "        differences = X_dim.reshape(len(X_dim), 1) - X_dim.reshape(1, len(X_dim))\n",
    "\n",
    "        sq_differences = differences ** 2\n",
    "\n",
    "        return 2.0 * K * (self.scaling - 2 * sq_differences) / self.scaling ** 2\n",
    "\n",
    "    def get_statistic_multiple_dim(self, samples, dim):\n",
    "        num_samples = len(samples)\n",
    "\n",
    "        log_pdf_gradients = self.grad_multiple(samples)\n",
    "        # n x 1\n",
    "        log_pdf_gradients = log_pdf_gradients[:, dim]\n",
    "        # n x n\n",
    "        K = self.kernel_matrix(samples)\n",
    "        assert K.shape[0]==K.shape[1]\n",
    "        # n x n\n",
    "        gradient_k_x = self.gradient_k_wrt_x(samples, K, dim)\n",
    "        assert gradient_k_x.shape[0] == gradient_k_x.shape[1]\n",
    "        # n x n\n",
    "        gradient_k_y = self.gradient_k_wrt_y(samples, K, dim)\n",
    "        # n x n \n",
    "        second_derivative = self.second_derivative_k(samples, K, dim)\n",
    "        assert second_derivative.shape[0] == second_derivative.shape[1]\n",
    "\n",
    "        # use broadcasting to mimic the element wise looped call\n",
    "        pairwise_log_gradients = log_pdf_gradients.reshape(num_samples, 1) \\\n",
    "                                 * log_pdf_gradients.reshape(1, num_samples)\n",
    "        A = pairwise_log_gradients * K\n",
    "\n",
    "        B = gradient_k_x * log_pdf_gradients\n",
    "        C = (gradient_k_y.T * log_pdf_gradients).T\n",
    "        D = second_derivative\n",
    "\n",
    "        V_statistic = A + B + C + D\n",
    "        #V_statistic =  C\n",
    "\n",
    "        stat = num_samples * np.mean(V_statistic)\n",
    "        return V_statistic, stat\n",
    "\n",
    "    def compute_pvalues_for_processes(self, U_matrix, chane_prob, num_bootstrapped_stats=300):\n",
    "        N = U_matrix.shape[0]\n",
    "        bootsraped_stats = np.zeros(num_bootstrapped_stats)\n",
    "\n",
    "        with util.NumpySeedContext(seed=10):\n",
    "            for proc in range(num_bootstrapped_stats):\n",
    "                # W = np.sign(orsetinW[:,proc])\n",
    "                W = simulatepm(N, chane_prob)\n",
    "                WW = np.outer(W, W)\n",
    "                st = np.mean(U_matrix * WW)\n",
    "                bootsraped_stats[proc] = N * st\n",
    "\n",
    "        stat = N * np.mean(U_matrix)\n",
    "\n",
    "        return float(np.sum(bootsraped_stats > stat)) / num_bootstrapped_stats\n",
    "\n",
    "    def is_from_null(self, alpha, samples, chane_prob):\n",
    "        dims = samples.shape[1]\n",
    "        boots = 10 * int(dims / alpha)\n",
    "        num_samples = samples.shape[0]\n",
    "        U = np.zeros((num_samples, num_samples))\n",
    "        for dim in range(dims):\n",
    "            U2, _ = self.get_statistic_multiple_dim(samples, dim)\n",
    "            U += U2\n",
    "\n",
    "        p = self.compute_pvalues_for_processes(U, chane_prob, boots)\n",
    "        return p, U\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sigma = np.array([[1, 0.2, 0.1], [0.2, 1, 0.4], [0.1, 0.4, 1]])\n",
    "def grad_log_correleted(x):\n",
    "    #sigmaInv = np.linalg.inv(sigma)\n",
    "    #return - np.dot(sigmaInv.T + sigmaInv, x) / 2.0\n",
    "    return -(x-mean)/variance\n",
    "\n",
    "#me = _GoodnessOfFitTest(grad_log_correleted)\n",
    "\n",
    "qm = _GoodnessOfFitTest(grad_log_correleted, scaling=sig2)\n",
    "#X = np.random.multivariate_normal([0, 0, 0], sigma, 200)\n",
    "\n",
    "p_val, U = qm.is_from_null(0.05, X, 0.1)\n",
    "print(p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(U, interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-statistic matrix from the new implementation\n",
    "H = kstein_result['H']\n",
    "plt.imshow(H, interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(U-H, interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(1, 5, 5)\n",
    "y = np.random.randint(1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, np.newaxis] - y[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
