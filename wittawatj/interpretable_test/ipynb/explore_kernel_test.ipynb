{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-sample test with mean embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import freqopttest.kernel as ker\n",
    "import scipy.stats as stats\n",
    "\n",
    "def me_kernel(X, locs, gamma):\n",
    "    \"\"\"Compute a X.shape[0] x locs.shape[0] Gaussian kernel matrix where\n",
    "    the width gamma is only applied to the data X.\"\"\"\n",
    "    n, d = X.shape\n",
    "    X = X/gamma\n",
    "    D2 = np.sum(X**2, 1)[:, np.newaxis] - 2*X.dot(locs.T) + np.sum(locs**2, 1)\n",
    "    K = np.exp(-D2)\n",
    "    return K\n",
    "\n",
    "def draw_freqs(J, d, seed=3):\n",
    "    old = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    freqs = np.random.randn(J, d)\n",
    "    np.random.set_state(old)\n",
    "    return freqs\n",
    "\n",
    "def t2_stat(X, Y, locs, gamma):\n",
    "    \"\"\"\n",
    "    locs: J x d\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    g = me_kernel(X, locs, gamma)\n",
    "    h = me_kernel(Y, locs, gamma)\n",
    "    Z = g-h\n",
    "    Sig = np.cov(Z.T)\n",
    "    W = np.mean(Z, 0)\n",
    "    # test statistic\n",
    "    s = np.linalg.solve(Sig, W).dot(n*W)\n",
    "    return s\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations to test\n",
    "# J = #locations\n",
    "J = 3\n",
    "#cen = (np.mean(X, 0) + np.mean(Y, 0))/2.0\n",
    "locs = draw_freqs(J, 2)\n",
    "\n",
    "\n",
    "# two Gaussian datasets\n",
    "n = 70\n",
    "d = 2\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "X = np.random.randn(n, d) \n",
    "Y = np.random.randn(n, d) + [0.5, 0]\n",
    "#Y = np.random.randn(n, d) \n",
    "#Y = np.random.randn(n, d)*1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def me_test_plot(X, Y, locs, gamma):\n",
    "    J = locs.shape[0]\n",
    "    # plot the data\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(X[:, 0], X[:, 1], 'xb', label='X')\n",
    "    plt.plot(Y[:, 0], Y[:, 1], 'xr', label='Y')\n",
    "    plt.plot(locs[:, 0], locs[:, 1], '*k', markersize=13, label='Test locs')\n",
    "    plt.legend()\n",
    "    \n",
    "    # compute the test statistic\n",
    "    #gamma = 1\n",
    "    s = t2_stat(X, Y, locs, gamma)\n",
    "    print('test stat s: %.4g' % s)\n",
    "\n",
    "    # compute the p-value under Chi2 with J degrees of freedom\n",
    "    p_value = stats.chi2.sf(s, J)\n",
    "    domain = np.linspace(stats.chi2.ppf(0.001, J), stats.chi2.ppf(0.9999, J), 200)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(domain, stats.chi2.pdf(domain, J), label='$\\chi^2$ (df=%d)'%J)\n",
    "    plt.stem([s], [stats.chi2.pdf(J, J)/2], 'or-', label='test stat')\n",
    "    plt.legend(loc='best', frameon=True)\n",
    "    plt.title('p-value: %.3g. test stat: %.3g'%(p_value, s))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "\n",
    "def best_loc2_testpower(X, Y, gamma, loc1):\n",
    "    \"\"\"Show a heatmap of Lambda(T) on many locations of the test points. \n",
    "    J=2 (two locations). Assume loc1 is given. Vary loc2 (2d). \"\"\"\n",
    "    \n",
    "    # For simplicity, we will assume that J=2 (two frequencies) \n",
    "    # and that one (loc1) is fixed. We will optimize loc2 (2-dimensional).\n",
    "    XY = np.vstack((X,Y))\n",
    "    max1, max2 = np.max(XY, 0)\n",
    "    min1, min2 = np.min(XY, 0)\n",
    "    #sd1, sd2 = np.std(XY, 0)\n",
    "    sd1, sd2 = (0, 0)\n",
    "    # form a frequency grid to try \n",
    "    nd1 = 30\n",
    "    nd2 = 30\n",
    "    loc1_cands = np.linspace(min1-sd1/2, max1+sd1/2, nd1)\n",
    "    loc2_cands = np.linspace(min2-sd2/2, max2+sd2/2, nd2)\n",
    "    lloc1, lloc2 = np.meshgrid(loc1_cands, loc2_cands)\n",
    "    # nd2 x nd1 x 2\n",
    "    loc3d = np.dstack((lloc1, lloc2))\n",
    "    # #candidates x 2\n",
    "    all_loc2s = np.reshape(loc3d, (-1, 2) )\n",
    "    \n",
    "    # all_locs = #candidates x J x 2\n",
    "    all_locs = np.array( [np.vstack((c, loc1)) for c in all_loc2s] )\n",
    "\n",
    "    # evaluate Lambda(T) on each candidate T on the grid. Size = (#candidates, )\n",
    "    stat_grid = np.array([t2_stat(X, Y, T, gamma) for T in all_locs])\n",
    "    stat_grid = np.reshape(stat_grid, (nd2, nd1) )\n",
    "    \n",
    "    #ax = fig.gca(projection='3d')\n",
    "    #ax.plot_surface(lloc1, lloc2, stat_grid, rstride=8, cstride=8, alpha=0.3)\n",
    "    #cset = ax.contourf(lloc1, lloc2, stat_grid, zdir='z', offset=0, cmap=cm.coolwarm)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.contourf(lloc1, lloc2, stat_grid)\n",
    "    plt.colorbar()\n",
    "\n",
    "    max_stat = np.max(stat_grid)\n",
    "    plt.xlabel('loc2 x')\n",
    "    plt.ylabel('loc2 y')\n",
    "    plt.title('fixed loc1=t1. $\\lambda(t1, t2)$ for all t2.')\n",
    "    #ax.view_init(elev=max_stat*2, azim=90)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# interactively select test locations\n",
    "def me_test_plot_interact(X, Y, loc1x=0, loc1y=0, loc2x=1, loc2y=1, gamma=1):\n",
    "    locs = np.array([[loc1x, loc1y], [loc2x, loc2y]])\n",
    "    me_test_plot(X, Y, locs, gamma)\n",
    "    loc1 = np.array([loc1x, loc1y])\n",
    "    best_loc2_testpower(X, Y, gamma, loc1)\n",
    "\n",
    "loc1_bnd = (-6, 6, 0.1)\n",
    "loc2_bnd = (-6, 6, 0.1)\n",
    "vs = interactive(me_test_plot_interact, X=fixed(X), Y=fixed(Y), loc1x=loc1_bnd, \n",
    "        loc1y=loc1_bnd, loc2x=loc2_bnd, loc2y=loc2_bnd, \n",
    "        gamma=(0.5, 20, 0.1));\n",
    "display(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing test locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as tensor\n",
    "import theano.tensor.nlinalg as nlinalg\n",
    "import theano.tensor.slinalg as slinalg\n",
    "\n",
    "def akgauss_theano(X, T, gamma):\n",
    "    \"\"\"Asymmetric kernel for the two sample test. Theano version.\n",
    "    :param gamma: width of the Gaussian kernel. \n",
    "    :return kernel matrix X.shape[0] x T.shape[0]\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    X = X/gamma\n",
    "\n",
    "    D2 = (X**2).sum(1).reshape((-1, 1)) - 2*X.dot(T.T) + tensor.sum(T**2, 1).reshape((1, -1))\n",
    "    K = tensor.exp(-D2)\n",
    "    return K\n",
    "\n",
    "seed = 4\n",
    "J = 2\n",
    "#def opt_me_lambda_kgauss(X, Y, J, seed):\n",
    "\"\"\"\n",
    "Optimize the empirical version of Lambda(T) i.e., the criterion used \n",
    "to optimize the test locations, for the test based \n",
    "on difference of mean embeddings with Gaussian kernel. \n",
    "Also optimize the Gaussian width.\n",
    "\n",
    ":param J: the number of test locations\n",
    ":return a theano function T |-> Lambda(T)\n",
    "\"\"\"\n",
    "st0 = np.random.get_state()\n",
    "np.random.seed(seed)\n",
    "\n",
    "n, d = X.shape\n",
    "# initialize Theano variables\n",
    "T = theano.shared(np.random.randn(J, d), name='T')\n",
    "#T = tensor.dmatrix(name='T')\n",
    "Xth = tensor.dmatrix('X')\n",
    "Yth = tensor.dmatrix('Y')\n",
    "it = theano.shared(1, name='iter')\n",
    "# Gaussian width\n",
    "gamma_init = 0.5\n",
    "gammath = theano.shared(gamma_init, name='gamma')\n",
    "\n",
    "g = akgauss_theano(Xth, T, gammath)\n",
    "h = akgauss_theano(Yth, T, gammath)\n",
    "# Z: n x J\n",
    "Z = g-h\n",
    "W = Z.sum(axis=0)/n\n",
    "# covariance \n",
    "Z0 = Z - W\n",
    "Sig = Z0.T.dot(Z0)/n\n",
    "\n",
    "# gradient computation does not support solve()\n",
    "#s = slinalg.solve(Sig, W).dot(n*W)\n",
    "s = nlinalg.matrix_inverse(Sig).dot(W).dot(W)*n\n",
    "gra_T, gra_gamma = tensor.grad(s, [T, gammath])\n",
    "func = theano.function(inputs=[Xth, Yth], outputs=s, \n",
    "                       updates=[(T, T+0.1*gra_T/it**0.5), (gammath, gammath+0.05*gra_gamma/it**0.5), (it, it+1) ] )\n",
    "                       #updates=[(T, T+0.1*gra_T), (it, it+1) ] )\n",
    "\n",
    "np.random.set_state(st0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient ascent\n",
    "max_iter = 400\n",
    "S = np.zeros(max_iter)\n",
    "Ts = np.zeros((max_iter, J, d))\n",
    "gams = np.zeros(max_iter)\n",
    "for t in range(max_iter):\n",
    "    # stochastic gradient descent\n",
    "    ind = np.random.choice(n, min(n, n), replace=False)\n",
    "    S[t] = func(X[ind, :], Y[ind, :])\n",
    "    Ts[t] = T.get_value()\n",
    "    gams[t] = gammath.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(S)\n",
    "plt.xlabel('gradient ascent iteration')\n",
    "plt.ylabel('$\\lambda(T)$')\n",
    "besti = np.argmax(S)\n",
    "print('highest objective: %.4g'%S[besti])\n",
    "print('best Locations: ')\n",
    "print(Ts[besti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Gaussian widths\n",
    "plt.plot(gams)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Gaussian width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
